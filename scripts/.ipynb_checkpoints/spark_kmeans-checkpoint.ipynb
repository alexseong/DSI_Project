{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nltk.data.path.append(\"/mnt1/nltk_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PUNCTUATION = set(string.punctuation)\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark as ps\n",
    "sc = ps.SparkContext('local[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = os.environ['AWS_ACCESS_KEY']\n",
    "SECRET_KEY = os.environ['AWS_SECRET_ACCESS_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wiki_rdd = sc.textFile('s3n://{}:{}@//jyt109/wiki_articles/part-00119'.format(ACCESS_KEY, SECRET_KEY))\n",
    "wiki_rdd = sc.textFile('s3a://{}:{}@jyt109/wiki_articles/part-00119'.format(ACCESS_KEY, SECRET_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = wiki_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wiki MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_rdd.cache()\n",
    "wiki_rdd.setName('wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#f = open('count.txt', 'w')\n",
    "#f.write(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_rdd_samples = sc.parallelize(wiki_rdd.take(100), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'{{Multiple issues| {{citation style|date=December 2014}} {{orphan|date=December 2014}} {{Underlinked'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_direct = wiki_rdd_samples.first()\n",
    "no_direct[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    regex = re.compile('<.+?>|[^a-zA-Z]')\n",
    "    clean_txt = regex.sub(' ', text)\n",
    "    tokens = clean_txt.split()\n",
    "    lowercased = [t.lower() for t in tokens]\n",
    "\n",
    "    no_punctuation = []\n",
    "    for word in lowercased:\n",
    "        punct_removed = ''.join([letter for letter in word if not letter in PUNCTUATION])\n",
    "        no_punctuation.append(punct_removed)\n",
    "    no_stopwords = [w for w in no_punctuation if not w in STOPWORDS]\n",
    "    \n",
    "    STEMMER = PorterStemmer()\n",
    "    stemmed = [STEMMER.stem(w) for w in no_stopwords]\n",
    "    return [w for w in stemmed if w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_rdd = wiki_rdd_samples.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'multipl',\n",
       " u'issu',\n",
       " u'citat',\n",
       " u'style',\n",
       " u'date',\n",
       " u'decemb',\n",
       " u'orphan',\n",
       " u'date',\n",
       " u'decemb',\n",
       " u'underlink']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = token_rdd.first()\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = token_rdd.flatMap(lambda x: x).distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tf(word_lst):\n",
    "    count_of_each_word = Counter(word_lst)\n",
    "    doc_word_count = len(word_lst) * 1.\n",
    "    return np.array([count_of_each_word[v] / doc_word_count if v in count_of_each_word else 0 for v in vocab])\n",
    "    \n",
    "tf_rdd = token_rdd.map(get_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ...,  0.01257862,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_first = tf_rdd.first()\n",
    "tf_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_doc_count = tf_rdd.count()\n",
    "total_doc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0, ..., 100,   0,   0])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times_words_in_dic = tf_rdd.map(lambda tf_lst: ((np.array(tf_first)>0)+0)).sum()\n",
    "times_words_in_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in divide\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "idf = np.log(total_doc_count / times_words_in_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_rdd = tf_rdd.map(lambda tf_vec: tf_vec * idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_nan_tfidf = tfidf_rdd.map(np.nan_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = KMeans.train(no_nan_tfidf, 10, maxIterations=100)\n",
    "centriods = model.centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ -1.79769313e+306,  -1.79769313e+306,              -inf, ...,\n",
       "          0.00000000e+000,  -1.79769313e+306,  -1.79769313e+306])]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centriods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
