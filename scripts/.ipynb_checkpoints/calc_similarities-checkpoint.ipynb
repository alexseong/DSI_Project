{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warc\n",
    "import gzip\n",
    "import boto\n",
    "from boto.s3.key import Key\n",
    "from gzipstream import GzipStreamFile\n",
    "from mrjob.job import MRJob\n",
    "import pyspark as ps\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from __future__ import print_function\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.mllib.clustering import LDAModel#, LDA\n",
    "from pyspark.mllib.linalg import Vectors, DenseVector, SparseVector\n",
    "from pyspark.ml.clustering import LDA, DistributedLDAModel, LocalLDAModel\n",
    "from pyspark.ml.feature import CountVectorizer, RegexTokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc = ps.SparkContext('local[4]')\n",
    "sqlContext = ps.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ACCESS_KEY = os.environ['AWS_ACCESS_KEY']\n",
    "SECRET_KEY = os.environ['AWS_SECRET_ACCESS_KEY']\n",
    "ENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\n",
    "DSI_CSTON_BUCKET = \"galvanize.dsi.capstone.alex\"\n",
    "OUT_BUCKET = \"s3a://{}:{}@{}\".format(ACCESS_KEY, SECRET_KEY, DSI_CSTON_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wet_path_file_name = 'wet_2016_list/2016-Dec-wet.path'\n",
    "no_of_doc_files = 1\n",
    "dec_2016_wet_list = sc.textFile(\"s3a://%s/%s\" % (DSI_CSTON_BUCKET, wet_path_file_name))\n",
    "doc_files = dec_2016_wet_list.take(no_of_doc_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = boto.connect_s3(ACCESS_KEY, SECRET_KEY, host='s3.amazonaws.com')\n",
    "pds = conn.get_bucket('commoncrawl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "url = []\n",
    "\n",
    "for file in doc_files:\n",
    "    k = Key(pds, file)\n",
    "    f = warc.WARCFile(fileobj=GzipStreamFile(k))\n",
    "\n",
    "    for i, document in enumerate(f):\n",
    "        if document['Content-Type'] != 'text/plain':\n",
    "            continue\n",
    "        \n",
    "        dat = document.payload.read()\n",
    "        data.append(str(dat))\n",
    "        url.append(str(document.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_df = pd.DataFrame(\n",
    "    {'contents': data,\n",
    "     'url': url\n",
    "    })\n",
    "rec_df = sqlContext.createDataFrame(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"contents\", outputCol=\"words\")\n",
    "rec_df = tokenizer.transform(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "rec_df = remover.transform(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rec_df = hashingTF.transform(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfModel = idf.fit(rec_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
